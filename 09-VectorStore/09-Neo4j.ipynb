{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z47qcQPDHZq_"
   },
   "source": [
    "# Neo4j Vector Index\n",
    "\n",
    "- Author: [Jongho](https://github.com/XaviereKU)\n",
    "- Design: \n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb)\n",
    "\n",
    "## Overview\n",
    "Neo4j is a Graph database backed by vector store and can be deployed locally or on cloud.\n",
    "\n",
    "In this tutorial we utilize its ability to store vectors only, and deal with its real ability, Graph database, later.\n",
    "\n",
    "To encode data into vector, we use ```OpenAIEmbedding```, but you can use any embedding you want.\n",
    "\n",
    "Furthermore, you need to note that you should read about ```Cypher```, declarative query language for Neo4j, to fully utilize Neo4j.\n",
    "\n",
    "We use some Cypher queries but will not go deeply. You can visit Cypher official document web site in References.\n",
    "\n",
    "For more information, visit [Neo4j](https://neo4j.com/).\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Setup Neo4j](#setup-neo4j)\n",
    "\t- [Getting started with Aura](#getting-started-with-aura)\n",
    "\t- [Getting started with Docker](#getting-started-with-docker)\n",
    "- [Credentials](#credentials)\n",
    "- [Initialization](#initialization)\n",
    "\t- [List Indexes](#list-indexs)\n",
    "\t- [Create Index](#create-index)\n",
    "\t- [Delete Index](#delete-index)\n",
    "\t- [Select Embedding model](#select-embeddings-model)\n",
    "\t- [Data Preprocessing](#data-preprocessing)\n",
    "- [Manage vector store](#manage-vector-store)\n",
    "\t- [Add items to vector store](#add-items-to-vector-store)\n",
    "\t- [Delete items from vector store](#delete-items-from-vector-store)\n",
    "\t- [Scroll items from vector store](#scroll-items-from-vector-store)\n",
    "\t- [(Advanced)Scroll items with query](#advanced-scroll-items-with-query)\n",
    "- [Similarity search](#similarity-search)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Cypher](https://neo4j.com/docs/cypher-manual/current/introduction/)\n",
    "- [Neo4j Docker Installation](https://hub.docker.com/_/neo4j)\n",
    "- [Neo4j Official Installation guide](https://neo4j.com/docs/operations-manual/current/installation/)\n",
    "- [Neo4j Python SDK document](https://neo4j.com/docs/api/python-driver/current/index.html)\n",
    "- [Neo4j document](https://neo4j.com/docs/)\n",
    "- [Langchain Neo4j document](https://python.langchain.com/docs/integrations/vectorstores/neo4jvector/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEk1SoFEfwjo"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n",
    "- We built ```Neo4jDB``` class from Python SDK of ```Neo4j```. Langchain also supports neo4j vector store class but it lacks some methods like delete. Look neo4j_interface.py in utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n9NVKk-Zf9Nq"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Pip install necessary package\n",
    "%pip install -qU neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IMx2hZNXf9QL"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_openai\",\n",
    "        \"neo4j\",\n",
    "        \"nltk\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N8C6pLTZf9Sb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"Your OpenAI API Key\",\n",
    "        \"LANGCHAIN_API_KEY\": \"Your LangChain API Key\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Neo4j\",\n",
    "        \"NEO4J_URI\": \"Your Neo4j Aura URI\",\n",
    "        \"NEO4J_USERNAME\": \"Your Neo4j Aura username\",\n",
    "        \"NEO4J_PASSWORD\": \"Your Neo4j Aura password\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as ```OPENAI_API_KEY``` in a ```.env``` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Neo4j\n",
    "We have two options to start with. Cloud or local deployment.\n",
    "\n",
    "In this tutorial, we will user Cloud service, called ```Aura``` provided by ```Neo4j```.\n",
    "\n",
    "But we will also describe how to deploy ```Neo4j``` with docker.\n",
    "\n",
    "### Getting started with Aura\n",
    "You can create a new **Neo4j Aura** account at [Neo4j](https://neo4j.com/) offical website.\n",
    "\n",
    "Visit web site and click Get Started Free at top right.\n",
    "\n",
    "If you done signing in, you will se a button, **Create instance** and after that you will see your username and password.\n",
    "\n",
    "To get your API Key, click **Download and continue** to download a txt file which contains API key to connect your **NEO4j Aura** .\n",
    "\n",
    "### Getting started with Docker\n",
    "We now describe how to run ```Neo4j``` using docker.\n",
    "\n",
    "To run Neo4j container, we use the following command.\n",
    "```\n",
    "docker run \\\n",
    "    -itd \\\n",
    "    --publish=7474:7474 --publish=7687:7687 \\\n",
    "    --volume=$HOME/neo4j/data:/data \\\n",
    "    --env=NEO4J_AUTH=none \\\n",
    "    --name neo4j \\\n",
    "    neo4j\n",
    "```\n",
    "\n",
    "You can visit **Neo4j Docker installation** reference to check more detailed information.\n",
    "\n",
    "**[NOTE]**\n",
    "* ```Neo4j``` also supports macOS, windows and Linux native deployment. Visit **Neo4j Official Installation guide** reference for more detail.\n",
    "* ```Neo4j``` community edition only supports one database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USvgdgjznDsd"
   },
   "source": [
    "## Credentials\n",
    "Now, if you successfully create your own account for Aura, you will get your ```NEO4J_URI```, ```NEO4J_USERNAME```, ```NEO4J_USERPASSWORD```.\n",
    "\n",
    "Add it to environmental variable above or add it to your ```.env``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QzFkuokSnL1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j database\n",
      "Connection info\n",
      "URI=neo4j+s://3ed1167e.databases.neo4j.io\n",
      "username=neo4j\n",
      "Neo4j version is above 5.23\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from utils.neo4j_interface import Neo4jDB\n",
    "\n",
    "# set uri, username, password\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "username = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "client = Neo4jDB(uri=uri, username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we established connection to Aura ```Neo4j``` database, connection info using ```get_api_key``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get connection info\n",
    "client.get_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWKVm4IkgHPn"
   },
   "source": [
    "## Initialization\n",
    "If you are succesfully connected to **Neo4j Aura**, there are some basic indexes already created.\n",
    "\n",
    "But, in this tutorial we will create a new indexand will add items(nodes) to it.\n",
    "\n",
    "To do this, we now look how to manage indexes.\n",
    "\n",
    "To manage indexes, we will see how to:\n",
    "* List indexes\n",
    "* Create new index\n",
    "* Delete index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdvN2pRtzpHB"
   },
   "source": [
    "### List Indexs\n",
    "Before create a new index, let's check indexes already in the ```Neo4j``` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8AgTNAl5zo3E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index_343aff4e', 'index_f7700477']\n"
     ]
    }
   ],
   "source": [
    "# get name list of indexes\n",
    "names = client.list_indexes()\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R94h5sY7oLyh"
   },
   "source": [
    "### Create Index\n",
    "\n",
    "Now we will create a new index.\n",
    "\n",
    "This can be done by calling `create_index` method, which will return an object connected to newly created index.\n",
    "\n",
    "If an index exists with the same name, the method will print out notification.\n",
    "\n",
    "When we create a new index, we must provide embedding object or dimension of vector, and ```metric``` to use for similarity search.\n",
    "\n",
    "In this tutorial we will pass `OpenAIEmbeddings` when we create a new index.\n",
    "\n",
    "\n",
    "**[ NOTE ]**\n",
    "- If you pass dimension of vector instead of embedding object, this must match the dimension of embeded vector of your choice of embedding model.\n",
    "- An embedding object must have ```embed_query``` and ```embed_documents``` methods.\n",
    "- ```metric``` is used to set distance method for similarity search. ```Neo4j``` supports **cosine** and **euclidean** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tR3bb-F5hCf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index information\n",
      "Index name: tutorial_index\n",
      "Node label: tutorial_node\n",
      "Similarity metric: COSINE\n",
      "Embedding dimension: 1536\n",
      "Embedding node property: embedding\n",
      "Text node property: text\n",
      "\n",
      "Index creation was successful\n",
      "['index_343aff4e', 'index_f7700477', 'tutorial_index']\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# set index_name and node_label\n",
    "index_name = \"tutorial_index\"\n",
    "node_label = \"tutorial_node\"\n",
    "\n",
    "# create a new index\n",
    "index = client.create_index(\n",
    "    embedding=embeddings, index_name=index_name, node_label=node_label\n",
    ")\n",
    "\n",
    "if isinstance(index, Neo4jDB):\n",
    "    print(\"Index creation was successful\")\n",
    "\n",
    "# check name list of indexes\n",
    "names = client.list_indexes()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKYPHPk40c4X"
   },
   "source": [
    "### Delete Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ua5yewan0TVy"
   },
   "source": [
    "We can delete specific index by calling `delete_index` method.\n",
    "\n",
    "Delete ```tutorial_index``` we created above and then create it again to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index deleted succesfully \n",
      "['index_343aff4e', 'index_f7700477']\n",
      "Created index information\n",
      "Index name: tutorial_index\n",
      "Node label: tutorial_node\n",
      "Similarity metric: COSINE\n",
      "Embedding dimension: 1536\n",
      "Embedding node property: embedding\n",
      "Text node property: text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete index\n",
    "client.delete_index(\"tutorial_index\")\n",
    "\n",
    "# print name list of indexes\n",
    "names = client.list_indexes()\n",
    "if \"tutorial_index\" not in names:\n",
    "    print(f\"Index deleted succesfully \")\n",
    "    print(names)\n",
    "\n",
    "# recreate the tutorial_index\n",
    "index = client.create_index(\n",
    "    embedding=embeddings, index_name=\"tutorial_index\", node_label=\"tutorial_node\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lwb_OMHunjwh"
   },
   "source": [
    "### Select Embeddings model\n",
    "\n",
    "We also can change embedding model.\n",
    "\n",
    "In this subsection we use ```text-embedding-3-large``` model to create a new index with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tRjB4EvXnoZM"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_large = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index information\n",
      "Index name: tutorial_index_2\n",
      "Node label: tutorial_node_2\n",
      "Similarity metric: COSINE\n",
      "Embedding dimension: 3072\n",
      "Embedding node property: embedding\n",
      "Text node property: text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new index\n",
    "index2 = client.create_index(\n",
    "    embedding=embeddings_large,\n",
    "    index_name=\"tutorial_index_2\",\n",
    "    node_label=\"tutorial_node_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtUJ2xSPrq3P"
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Below is the preprocessing process for general documents.\n",
    "\n",
    "- Need to extract **metadata** from documents\n",
    "- Filter documents by minimum length.\n",
    "  \n",
    "- Determine whether to use ```basename``` or not. Default is ```False```.\n",
    "  - ```basename``` denotes the last value of the filepath.\n",
    "  - For example, **document.pdf** will be the ```basename``` for the filepath **./data/document.pdf** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bmQI6bOsvJbu"
   },
   "outputs": [],
   "source": [
    "# This is a long document we can split up.\n",
    "data_path = \"./data/the_little_prince.txt\"\n",
    "with open(data_path, encoding=\"utf8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYdoMc4zvPe2",
    "outputId": "83cff661-a0bd-4ac3-d5dd-52c61ebd1627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The Little Prince\n",
      "Written By Antoine de Saiot-Exupery (1900〜1944)'\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# define text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# split raw text by splitter.\n",
    "split_docs = text_splitter.create_documents([raw_text])\n",
    "\n",
    "# print one of documents to check its structure\n",
    "print(split_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we preprocess splited document to extract author, page and source metadata while fit the data to store it into `Neo4j`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gGJ_bBJcw5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The Little Prince\n",
      "Written By Antoine de Saiot-Exupery (1900〜1944)' metadata={'source': 'the_little_prince.txt', 'page': 1, 'author': 'Saiot-Exupery'}\n"
     ]
    }
   ],
   "source": [
    "# preprocess raw documents\n",
    "processed_docs = client.preprocess_documents(\n",
    "    split_docs=split_docs,\n",
    "    metadata_keys=[\"source\", \"page\", \"author\"],\n",
    "    min_length=5,\n",
    "    use_basename=True,\n",
    "    source=data_path,\n",
    "    author=\"Saiot-Exupery\",\n",
    ")\n",
    "\n",
    "# print one of preprocessed document to chekc its structure\n",
    "print(processed_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B7xc2p3lXPV"
   },
   "source": [
    "## Manage vector store\n",
    "Once you have created your vector store, we can interact with it by adding and deleting different items.\n",
    "\n",
    "Also, you can scroll data from the store with filter or with ```Cypher``` query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxxP2ecAohWb"
   },
   "source": [
    "\n",
    "### Add items to vector store\n",
    "\n",
    "We can add items to our vector store by using the ```upsert_documents``` or ```upsert_documents_parallel``` method.\n",
    "\n",
    "If you pass ids along with documents, then ids will be used, but if you do not pass ids, it will be created based `page_content` using md5 hash function.\n",
    "\n",
    "Basically, ```upsert_document``` and ```upsert_document_parallel``` methods do upsert not insert, based on **id** of the item.\n",
    "\n",
    "So if you provided id and want to update data, you must provide the same id that you provided at first upsertion.\n",
    "\n",
    "We will upsert data to index, tutorial_index, with ```upsert_documents``` method for the first half, and with ```upsert_documents_parallel``` for the second half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7cS0FHgalwPm"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826cd68e8ba547ef8726bd7b7dc33670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserting documents...:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359\n",
      "Manual Ids == Output Ids: True\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "# make ids for each document\n",
    "uuids = [str(uuid4()) for _ in range(len(processed_docs))]\n",
    "\n",
    "\n",
    "# upsert documents\n",
    "total_number = len(processed_docs)\n",
    "upsert_result = index.upsert_documents(\n",
    "    processed_docs[: total_number // 2], ids=uuids[: total_number // 2]\n",
    ")\n",
    "\n",
    "# upsert documents parallel\n",
    "upsert_parallel_result = index.upsert_documents_parallel(\n",
    "    processed_docs[total_number // 2 :],\n",
    "    batch_size=32,\n",
    "    max_workers=8,\n",
    "    ids=uuids[total_number // 2 :],\n",
    ")\n",
    "\n",
    "result = upsert_result + upsert_parallel_result\n",
    "\n",
    "# check number of ids upserted\n",
    "print(len(result))\n",
    "\n",
    "# check manual ids are the same as output ids\n",
    "print(\"Manual Ids == Output Ids:\", sorted(result) == sorted(uuids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqP_zpiOobdJ"
   },
   "source": [
    "### Delete items from vector store\n",
    "\n",
    "We can delete nodes by filter or ids with `delete_node` method.\n",
    "\n",
    "\n",
    "For example, we will delete **the first page**, that is `page` 1, of the little prince, and try to scroll it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OWmeKCqLo3ht"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# define filter\n",
    "filters = {\"page\": 1, \"author\": \"Saiot-Exupery\"}\n",
    "\n",
    "# call delete_node method\n",
    "result = index.delete_node(filters=filters)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll nodes by filter\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# define filter for scroll data\n",
    "filters = {\"page\": 1, \"author\": \"Saiot-Exupery\"}\n",
    "\n",
    "# call scroll method\n",
    "result = index.scroll_nodes(filters=filters)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we successfully deleted a node which satisfies the given filter.\n",
    "\n",
    "To make sure only 1 data deleted, let's check the total number of nodes in index `vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in vector: 1358\n"
     ]
    }
   ],
   "source": [
    "# scroll vector index\n",
    "result = index.scroll_nodes(limit=None)\n",
    "print(\"The number of nodes in vector: {}\".format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '8f9ed6b2-4fc5-4c23-a32b-d53acc72a68a',\n",
       " 'metadata': {'author': 'Saiot-Exupery',\n",
       "  'text': '[ Antoine de Saiot-Exupery ]',\n",
       "  'source': 'the_little_prince.txt',\n",
       "  'page': 2}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(result, key=lambda x: x[\"metadata\"][\"page\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now delete 5 items using ```ids```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# delete item by ids\n",
    "ids = uuids[1:6]\n",
    "\n",
    "# call delete_node method\n",
    "result = index.delete_node(ids=ids)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in vector: 1353\n"
     ]
    }
   ],
   "source": [
    "# scroll vector index\n",
    "result = index.scroll_nodes(limit=None)\n",
    "print(\"The number of nodes in vector: {}\".format(len(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll items from vector store\n",
    "You can scroll items(nodes) in store by calling ```scroll_nodes``` method with filters or ids.\n",
    "\n",
    "If you are you scroll by filter and you passed keys and values, those will be treated as **MUST** condition, which means the nodes that match all the conditions will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll nodes by filter\n",
      "[{'id': '8fcae3d1-8d41-4010-9458-6324a87c6cb4', 'metadata': {'author': 'Saiot-Exupery', 'text': 'learned to fly a plane. Five years later, he would leave the military in order to begin flying air', 'source': 'the_little_prince.txt', 'page': 10}}]\n"
     ]
    }
   ],
   "source": [
    "# define scroll filter\n",
    "filters = {\"author\": \"Saiot-Exupery\", \"page\": 10}\n",
    "\n",
    "# get nodes\n",
    "result = index.scroll_nodes(filters=filters)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll nodes by ids\n",
      "[{'id': '9f4790f0-6f1b-428c-87c7-dbc3b909852a', 'metadata': {'author': 'Saiot-Exupery', 'text': 'For Saint-Exupéry, it was a grand adventure - one with dangers lurking at every corner. Flying his', 'source': 'the_little_prince.txt', 'page': 12}}]\n"
     ]
    }
   ],
   "source": [
    "# get nodes by ids\n",
    "result = index.scroll_nodes(ids=uuids[11])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Scroll items with query\n",
    "Provided method, ```scroll_nodes``` only support **AND** condition for multiple (key, value) pairs.\n",
    "\n",
    "But if you use ```Cypher```, more complicated condition can be used to scroll items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll nodes by query\n",
      "{'n.page': 10, 'n.author': 'Saiot-Exupery', 'n.text': 'learned to fly a plane. Five years later, he would leave the military in order to begin flying air'}\n",
      "{'n.page': 11, 'n.author': 'Saiot-Exupery', 'n.text': 'to begin flying air mail between remote settlements in the Sahara desert.'}\n",
      "{'n.page': 12, 'n.author': 'Saiot-Exupery', 'n.text': 'For Saint-Exupéry, it was a grand adventure - one with dangers lurking at every corner. Flying his'}\n"
     ]
    }
   ],
   "source": [
    "# create cypher query\n",
    "query = \"MATCH (n) WHERE n.page IN [10,11,12] AND n.author='Saiot-Exupery' RETURN n.page, n.author, n.text\"\n",
    "\n",
    "# scroll items with query\n",
    "result = index.scroll_nodes(query=query)\n",
    "\n",
    "for item in result:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search\n",
    "As ```Neo4j``` supports vector database, you can also do similarity search.\n",
    "\n",
    "The similarity is calculated by the metric you set when you created the index to search on.\n",
    "\n",
    "In this tutorial we will search items on **tutorial_index** , which has metric **cosine** .\n",
    "\n",
    "To do search, we call ```search``` method.\n",
    "\n",
    "You can pass the raw text(to ```query``` paramter), or embeded vector of the text(to ```embeded_query``` paramter) when calling ```search```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT BY RAW QUERY\n",
      "{'text': '\"My friend the fox--\" the little prince said to me.', 'metadata': {'id': '70d75baa-3bed-4751-b0cf-98157e190756', 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt', 'page': 1087, 'embedding': None}, 'score': 0.947}\n",
      "{'text': 'And the little prince asked himself:', 'metadata': {'id': '9e779e02-1d2b-4252-a8f4-78bae7866af5', 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt', 'page': 492, 'embedding': None}, 'score': 0.946}\n",
      "\n",
      "RESULT BY EMBEDED QUERY\n",
      "{'text': '\"My friend the fox--\" the little prince said to me.', 'metadata': {'id': '70d75baa-3bed-4751-b0cf-98157e190756', 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt', 'page': 1087, 'embedding': None}, 'score': 0.947}\n",
      "{'text': 'And the little prince asked himself:', 'metadata': {'id': '9e779e02-1d2b-4252-a8f4-78bae7866af5', 'author': 'Saiot-Exupery', 'source': 'the_little_prince.txt', 'page': 492, 'embedding': None}, 'score': 0.946}\n"
     ]
    }
   ],
   "source": [
    "# do search. top_k is the number of documents in the result\n",
    "res_with_text = index.search(query=\"Does the little prince have a friend?\", top_k=5)\n",
    "\n",
    "# print out top 2 results\n",
    "print(\"RESULT BY RAW QUERY\")\n",
    "for i in range(2):\n",
    "    print(res_with_text[i])\n",
    "\n",
    "# embed query\n",
    "embeded_query = embeddings.embed_query(\"Does the little prince have a friend?\")\n",
    "\n",
    "# do search with embeded vector value\n",
    "res_with_embed = index.search(embeded_query=embeded_query, top_k=5)\n",
    "\n",
    "# print out top 2 results\n",
    "print()\n",
    "print(\"RESULT BY EMBEDED QUERY\")\n",
    "for i in range(2):\n",
    "    print(res_with_embed[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!\n",
    "\n",
    "You can now do the basics of how to use Neo4j.\n",
    "\n",
    "If you want to do more advanced tasks, please refer to `Neo4j` official API documents and official Python SDK of `Neo4j` API documents."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
